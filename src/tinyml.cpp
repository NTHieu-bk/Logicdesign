#include "tinyml.h"
#include "global.h"
#include "dht_anomaly_model2.h"  
// ============================================================
// PH·∫¶N 1: KHAI B√ÅO BI·∫æN TO√ÄN C·ª§C & TENSORFLOW OBJECTS
// ============================================================

// Bi·∫øn tr·∫°ng th√°i ƒë·ªÉ Web Server ƒë·ªçc (ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a extern trong global.h)
MLSystemState current_ml_state = ML_STATE_NORMAL;
float current_anomaly_score = 0.0f;
float current_anomaly_ratio = 0.0f;
String current_advice_msg = "ƒêang kh·ªüi t·∫°o...";
namespace {
    // --- C·∫•u h√¨nh TensorFlow Lite Micro ---
    tflite::ErrorReporter *error_reporter = nullptr;
    const tflite::Model *model = nullptr;
    tflite::MicroInterpreter *interpreter = nullptr;
    TfLiteTensor *input = nullptr;
    TfLiteTensor *output = nullptr;
    
    // V√πng nh·ªõ cho TFLite (Tinh ch·ªânh k√≠ch th∆∞·ªõc n·∫øu b·ªã l·ªói b·ªô nh·ªõ)
    constexpr int kTensorArenaSize = 8 * 1024; 
    uint8_t tensor_arena[kTensorArenaSize];

    // --- C·∫•u h√¨nh Logic & L·ªçc nhi·ªÖu ---
    constexpr int   WINDOW_SIZE       = 10;    // K√≠ch th∆∞·ªõc c·ª≠a s·ªï l·ªçc trung b√¨nh
    constexpr int   HISTORY_SIZE      = 30;    // L·ªãch s·ª≠ ph√°n ƒëo√°n (30 l·∫ßn ƒëo)
    constexpr float ANOMALY_THRESHOLD = 0.7f; // Ng∆∞·ª°ng ƒëi·ªÉm s·ªë (>0.7 l√† b·∫•t th∆∞·ªùng)
    
    // Gi·ªõi h·∫°n chu·∫©n h√≥a (Min-Max Normalization)
    // C·∫ßn kh·ªõp v·ªõi l√∫c b·∫°n train model Python
    constexpr float TEMP_MIN = 0.0f;
    constexpr float TEMP_MAX = 80.0f;
    constexpr float HUM_MIN  = 0.0f;
    constexpr float HUM_MAX  = 100.0f;

    // Bi·∫øn cho b·ªô l·ªçc trung b√¨nh tr∆∞·ª£t (Moving Average)
    static float temp_window[WINDOW_SIZE] = {0.0f};
    static float hum_window[WINDOW_SIZE]  = {0.0f};
    static int   window_idx    = 0;
    static float sum_temp      = 0.0f;
    static float sum_hum       = 0.0f;

    // Bi·∫øn cho Logic M√°y tr·∫°ng th√°i (State Machine)
    bool prediction_history[HISTORY_SIZE] = {false}; 
    int  history_idx = 0;
    int  consec_anomalies = 0; // ƒê·∫øm s·ªë l·ªói li√™n ti·∫øp
    
    // Bi·∫øn th·ªëng k√™
    long total_samples = 0;
    long total_anomalies_detected = 0;
}

// PH·∫¶N 2: H√ÄM H·ªñ TR·ª¢ TFLITE V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU

void setupTinyML() {
    Serial.println("Initializing TensorFlow Lite Micro...");

    static tflite::MicroErrorReporter micro_error_reporter;
    error_reporter = &micro_error_reporter;

    // 1. Load Model TFLite
    model = tflite::GetModel(dht_anomaly_model2_tflite);
    if (model->version() != TFLITE_SCHEMA_VERSION) {
        error_reporter->Report("Model version mismatch!");
        return;
    }

    // 2. Kh·ªüi t·∫°o Interpreter
    static tflite::AllOpsResolver resolver;
    static tflite::MicroInterpreter static_interpreter(
        model, resolver, tensor_arena, kTensorArenaSize, error_reporter);
    interpreter = &static_interpreter;

    // 3. C·∫•p ph√°t b·ªô nh·ªõ Tensor
    if (interpreter->AllocateTensors() != kTfLiteOk) {
        error_reporter->Report("AllocateTensors() failed");
        return;
    }

    // 4. L·∫•y con tr·ªè Input/Output
    input = interpreter->input(0);
    output = interpreter->output(0);

    Serial.println("‚úÖ TFLite Init Success!");
}

// Ti·ªÅn x·ª≠ l√Ω: L·ªçc nhi·ªÖu + Chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ [0, 1]
static void preprocessData(float raw_temp, float raw_hum, float &norm_temp, float &norm_hum) {
    // A. Moving Average (L·ªçc nhi·ªÖu gai)
    sum_temp -= temp_window[window_idx];
    sum_hum  -= hum_window[window_idx];
    
    temp_window[window_idx] = raw_temp;
    hum_window[window_idx]  = raw_hum;
    
    sum_temp += raw_temp;
    sum_hum  += raw_hum;
    
    window_idx = (window_idx + 1) % WINDOW_SIZE;

    float filt_temp = sum_temp / WINDOW_SIZE;
    float filt_hum  = sum_hum  / WINDOW_SIZE;

    // B. Min-Max Normalization
    norm_temp = (filt_temp - TEMP_MIN) / (TEMP_MAX - TEMP_MIN);
    norm_hum  = (filt_hum  - HUM_MIN)  / (HUM_MAX  - HUM_MIN);

    // K·∫πp gi√° tr·ªã [0, 1]
    if (norm_temp < 0.0f) norm_temp = 0.0f; if (norm_temp > 1.0f) norm_temp = 1.0f;
    if (norm_hum  < 0.0f) norm_hum  = 0.0f; if (norm_hum  > 1.0f) norm_hum  = 1.0f;
}

//  Suy lu·∫≠n AI
static bool runInference(float norm_temp, float norm_hum, float &out_score) {
    input->data.f[0] = norm_temp;
    input->data.f[1] = norm_hum;

    if (interpreter->Invoke() != kTfLiteOk) {
        return false;
    }

    out_score = output->data.f[0];
    return true;
}


// PH·∫¶N 3: STATE MACHINE - C·∫¨P NH·∫¨T TR·∫†NG TH√ÅI H·ªÜ TH·ªêNG D·ª∞A TR√äN K·∫æT QU·∫¢ AI

// Logic 1: ƒê∆∞a ra l·ªùi khuy√™n h√†nh ƒë·ªông
// Trong file tinyml.cpp

String getSmartAdvice(float temp, float hum, float ai_score) {
    // B√°o ch√°y (AI Score cao) 
    if (ai_score > ANOMALY_THRESHOLD) {
        return "üö® C·∫¢NH B√ÅO: NGHI C√ì CH√ÅY!<br>KI·ªÇM TRA NGAY!";
    }

    String advice = "";
    bool has_msg = false; // C·ªù ƒë√°nh d·∫•u xem ƒë√£ c√≥ d√≤ng n√†o ch∆∞a

    // --- Ki·ªÉm tra Nhi·ªát ƒë·ªô ---
    if (temp > 32.0) {
        advice += "üî• N√≥ng qu√°! B·∫≠t qu·∫°t/AC.";
        has_msg = true;
    } 
    else if (temp < 18.0) {
        advice += "‚ùÑÔ∏è L·∫°nh! B·∫≠t s∆∞·ªüi/M·∫∑c ·∫•m.";
        has_msg = true;
    }

    // --- Ki·ªÉm tra ƒê·ªô ·∫©m ---
    if (hum > 80.0) {
        if (has_msg) advice += "<br>"; // N·∫øu ·ªü tr√™n c√≥ ch·ªØ r·ªìi th√¨ xu·ªëng d√≤ng
        advice += "üíß ·∫®m ∆∞·ªõt! B·∫≠t h√∫t ·∫©m/Dry.";
        has_msg = true;
    } 
    else if (hum < 40.0) {
        if (has_msg) advice += "<br>"; // Xu·ªëng d√≤ng
        advice += "üåµ Kh√¥ hanh! B·∫≠t phun s∆∞∆°ng.";
        has_msg = true;
    }

    // --- K·∫øt lu·∫≠n ---
    if (advice == "") {
        return "‚úÖ M√¥i tr∆∞·ªùng l√Ω t∆∞·ªüng.";
    }
    
    return advice;
}

// Logic 2: M√°y tr·∫°ng th√°i (State Machine) ƒë·ªÉ ch·ªët ƒë√®n b√°o
static void updateStateLogic(bool is_anomaly_now) {
    // C·∫≠p nh·∫≠t l·ªãch s·ª≠
    prediction_history[history_idx] = is_anomaly_now;
    history_idx = (history_idx + 1) % HISTORY_SIZE;

    // ƒê·∫øm l·ªói trong c·ª≠a s·ªï 30 m·∫´u
    int total_in_window = 0;
    for(int i=0; i<HISTORY_SIZE; i++) {
        if(prediction_history[i]) total_in_window++;
    }

    // ƒê·∫øm l·ªói li√™n ti·∫øp
    if (is_anomaly_now) consec_anomalies++;
    else consec_anomalies = 0;

    // --- RA QUY·∫æT ƒê·ªäNH ---
    // TH1: Ch√°y th·∫≠t (Li√™n ti·∫øp >= 5 l·∫ßn HO·∫∂C T·ªïng > 20/30 l·∫ßn)
    if (consec_anomalies >= 5 || total_in_window > 20) {
        current_ml_state = ML_STATE_WARNING; 
    }
    // TH2: Nghi v·∫•n l·ªói Sensor (L√°c ƒë√°c < 5 l·∫ßn)
    else if (total_in_window > 0 && total_in_window <= 5) {
        current_ml_state = ML_STATE_SENSOR_CHECK;
    }
    // TH3: B√¨nh th∆∞·ªùng
    else {
        current_ml_state = ML_STATE_NORMAL;
    }
    
    // C·∫≠p nh·∫≠t t·ª∑ l·ªá th·ªëng k√™
    current_anomaly_ratio = (float)total_in_window / HISTORY_SIZE * 100.0f;
}

// PH·∫¶N 4: TINYML

void tiny_ml_task(void *pvParameters) {
    setupTinyML();
    vTaskDelay(pdMS_TO_TICKS(2000)); // Ch·ªù ·ªïn ƒë·ªãnh

    while (1) {
        // 1. L·∫•y d·ªØ li·ªáu th√¥
        float raw_temp = glob_temperature;
        float raw_hum  = glob_humidity;

        // 2. Ti·ªÅn x·ª≠ l√Ω
        float norm_temp, norm_hum;
        preprocessData(raw_temp, raw_hum, norm_temp, norm_hum);

        // 3. Ch·∫°y AI
        float score = 0.0f;
        if (runInference(norm_temp, norm_hum, score)) {
            current_anomaly_score = score;
        } else {
            score = 0.0f; // AI l·ªói th√¨ coi nh∆∞ 0
        }

        // 4. Logic Tr·ª£ l√Ω (C·∫≠p nh·∫≠t l·ªùi khuy√™n)
        current_advice_msg = getSmartAdvice(raw_temp, raw_hum, score);

        // 5. Logic Tr·∫°ng th√°i (C·∫≠p nh·∫≠t ƒë√®n b√°o)
        bool is_anomaly = (score > ANOMALY_THRESHOLD);
        if (is_anomaly) total_anomalies_detected++;
        total_samples++;

        updateStateLogic(is_anomaly);

        // 6. Ngh·ªâ 2 gi√¢y (ƒê·ªìng b·ªô h·ªá th·ªëng)
        vTaskDelay(pdMS_TO_TICKS(2000));
    }
}